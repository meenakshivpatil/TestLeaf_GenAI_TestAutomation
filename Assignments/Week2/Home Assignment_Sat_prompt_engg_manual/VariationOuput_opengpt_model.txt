Using openai/gpt-oss-20b model, it seems it is giving better output, the test cases are more elaborated.

https://api.groq.com/openai/v1/chat/completions


Request:
{
  "model": "openai/gpt-oss-20b",
  "messages": [{
      "role": "user",
      "content": "Generate Non functional test cases for the use case in non tabular format: Title: Update Debit Card Limits\n\nAs a bank customer,\nI want to update the transaction limits on my debit card,\nSo that I can control my spending and enhance security based on my personal preferences.\n\nAcceptance Criteria:\n\nLimit Types:\nThe user should be able to update different types of limits, such as:\n\nDaily purchase limit\n\nDaily ATM withdrawal limit\n\nContactless payment limit (if applicable)\n\nValidation:\n\nThe system should validate the new limit values to ensure they are within the allowed range set by the bank.\n\nThe user should receive an error message if they enter an invalid or unsupported limit.\n\nAuthentication:\n\nThe user must be authenticated (e.g., via login, OTP, or biometric) before updating the limits.\n\nConfirmation:\n\nAfter submitting the change, the user should receive a confirmation message indicating the new limits are in effect.\n\nOptionally, a confirmation email or push notification should be sent.\n\nAudit Trail:\n\nThe change should be logged in the system for auditing purposes and viewable in the user’s activity history."
  }],
  "temperature": 0.6
}


Response:
{
    "id": "chatcmpl-f3511f8c-641d-4466-93d7-2fec917988b4",
    "object": "chat.completion",
    "created": 1760623724,
    "model": "openai/gpt-oss-20b",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "**Non‑Functional Test Cases – “Update Debit Card Limits” Use Case**\n\nBelow are the non‑functional test scenarios that will be executed against the “Update Debit Card Limits” feature.  \nEach scenario is presented as a short narrative that describes the **objective**, the **steps to perform**, and the **expected outcome**.  The format is intentionally free of tables so that it can be read as a simple checklist or incorporated directly into a test‑management tool that prefers a textual description.\n\n---\n\n### 1. Performance – Response Time\n\n**Objective**  \nVerify that the limit‑update operation completes within the target response time under normal load.\n\n**Steps**  \n1. Log in to the banking application using a valid user account.  \n2. Navigate to the “Debit Card Limits” screen.  \n3. Change the daily purchase limit to a value within the allowed range.  \n4. Submit the change.  \n5. Record the time from the click of the “Submit” button to the appearance of the confirmation message.\n\n**Expected Outcome**  \nThe total response time should be less than **2 seconds** for a single transaction on a standard network connection.\n\n---\n\n### 2. Performance – Load & Concurrency\n\n**Objective**  \nEnsure that the system can handle multiple simultaneous limit‑update requests without degradation.\n\n**Steps**  \n1. Simulate **200** concurrent users (e.g., via a load‑testing tool).  \n2. Each simulated user logs in, navigates to the limits screen, and submits a valid limit change.  \n3. Monitor the average response time and error rate.\n\n**Expected Outcome**  \nAverage response time remains below **3 seconds** and error rate stays under **1 %**.\n\n---\n\n### 3. Security – Authentication & Session Management\n\n**Objective**  \nConfirm that only authenticated sessions can perform limit changes and that session tokens expire correctly.\n\n**Steps**  \n1. Log in using a valid account and obtain a session token.  \n2. In a separate browser tab, delete the session cookie or invalidate the token.  \n3. Attempt to submit a limit change.  \n4. Observe the system’s response.\n\n**Expected Outcome**  \nThe system rejects the request, displays an authentication error, and redirects the user to the login page.\n\n---\n\n### 4. Security – Input Validation & Injection Prevention\n\n**Objective**  \nVerify that the system rejects malformed or malicious input and is resistant to injection attacks.\n\n**Steps**  \n1. On the limits screen, enter a SQL injection string (e.g., `1; DROP TABLE Users;`) into the limit field.  \n2. Submit the change.  \n3. Repeat with a script injection (`<script>alert('XSS')</script>`).\n\n**Expected Outcome**  \nThe system treats the input as invalid, returns a generic “Invalid value” error, and does not execute any unintended commands or scripts.\n\n---\n\n### 5. Security – Data Encryption in Transit & At Rest\n\n**Objective**  \nConfirm that all data exchanged during the limit‑update process is encrypted.\n\n**Steps**  \n1. Capture network traffic using a packet sniffer while performing a limit change.  \n2. Inspect the payload to ensure it is not plain text.  \n3. Verify that the database stores limit values in an encrypted field (via a database audit tool).\n\n**Expected Outcome**  \nAll transmitted data is protected by TLS 1.2+ and stored values are encrypted with a secure key‑management system.\n\n---\n\n### 6. Usability – Accessibility\n\n**Objective**  \nEnsure that the limits screen is accessible to users with disabilities.\n\n**Steps**  \n1. Load the limits page in a screen‑reader environment (e.g., NVDA or VoiceOver).  \n2. Navigate the form using only keyboard shortcuts.  \n3. Verify that all form controls have descriptive labels and that error messages are announced.\n\n**Expected Outcome**  \nThe screen is fully navigable via keyboard, labels are correctly read by the screen‑reader, and error messages are conveyed audibly.\n\n---\n\n### 7. Reliability – Error Handling & Recovery\n\n**Objective**  \nValidate that the system gracefully handles transient failures during a limit update.\n\n**Steps**  \n1. Simulate a database connection drop just before submitting the change.  \n2. Attempt to submit the new limits.  \n3. Observe the system’s response and retry logic.\n\n**Expected Outcome**  \nThe system displays a user‑friendly error message (“Unable to process request. Please try again.”), logs the failure, and allows the user to retry without losing entered data.\n\n---\n\n### 8. Availability – Redundancy & Failover\n\n**Objective**  \nConfirm that the limit‑update feature remains available during a server failover.\n\n**Steps**  \n1. Trigger a planned failover of the application server (e.g., by stopping the primary instance).  \n2. While the failover is in progress, attempt to update limits from a client device.  \n3. Monitor whether the request is routed to the standby instance and processed.\n\n**Expected Outcome**  \nThe request is handled by the standby server, the user receives the confirmation message, and no downtime is experienced.\n\n---\n\n### 9. Scalability – Data Volume\n\n**Objective**  \nEnsure that the audit trail can grow without impacting performance.\n\n**Steps**  \n1. Perform limit updates repeatedly (e.g., 10,000 times) for a single user.  \n2. Measure the time to retrieve the user’s activity history after each batch of updates.\n\n**Expected Outcome**  \nRetrieval time increases linearly but remains within acceptable limits (< 5 seconds for 10,000 records).\n\n---\n\n### 10. Maintainability – Logging & Monitoring\n\n**Objective**  \nVerify that all limit changes are properly logged and can be monitored.\n\n**Steps**  \n1. Update a limit value.  \n2. Inspect the application logs to confirm that an entry is created with user ID, timestamp, old value, new value, and transaction ID.  \n3. Check that monitoring dashboards (e.g., Splunk, ELK) display the event in real time.\n\n**Expected Outcome**  \nLogs are complete, structured, and searchable; monitoring alerts fire if the rate of limit changes exceeds a predefined threshold.\n\n---\n\n### 11. Compatibility – Browser & Device\n\n**Objective**  \nConfirm that the limits screen functions correctly across supported browsers and devices.\n\n**Steps**  \n1. Open the banking application on Chrome, Firefox, Safari, Edge, and Internet Explorer 11.  \n2. Repeat the limit‑update flow on each browser.  \n3. Perform the same flow on mobile browsers (iOS Safari, Android Chrome) and on the native mobile app.\n\n**Expected Outcome**  \nAll browsers and devices display the form correctly, accept input, and show the confirmation message without layout issues.\n\n---\n\n### 12. Internationalization & Localization\n\n**Objective**  \nEnsure that the limits screen displays correctly in supported languages.\n\n**Steps**  \n1. Switch the application language to Spanish, French, and Arabic.  \n2. Navigate to the limits screen and perform a limit update.  \n3. Verify that all text, error messages, and numbers are correctly translated and formatted (e.g., currency symbols, decimal separators).\n\n**Expected Outcome**  \nThe UI reflects the selected language accurately, and number formatting follows locale conventions.\n\n---\n\n### 13. Disaster Recovery – Data Integrity\n\n**Objective**  \nValidate that limit changes survive a catastrophic failure and can be restored.\n\n**Steps**  \n1. Back up the database snapshot immediately after a limit update.  \n2. Simulate a data loss event (e.g., delete the relevant table).  \n3. Restore from the backup.  \n4. Verify that the limit values and audit records are intact.\n\n**Expected Outcome**  \nRestored data matches the state before the failure; the user’s updated limits are preserved.\n\n---\n\n### 14. Regulatory Compliance – Data Retention\n\n**Objective**  \nConfirm that audit logs are retained for the mandated period (e.g., 7 years) and are protected from tampering.\n\n**Steps**  \n1. Review the audit log retention policy in the system configuration.  \n2. Verify that log entries older than the retention period are archived or deleted automatically.  \n3. Attempt to modify an old audit record and confirm that the system blocks the action.\n\n**Expected Outcome**  \nAudit logs comply with regulatory requirements, are immutable, and are purged or archived according to policy.\n\n---\n\n### 15. Accessibility – Color Contrast & Font Size\n\n**Objective**  \nEnsure that the limits screen meets WCAG 2.1 AA guidelines for color contrast and font scaling.\n\n**Steps**  \n1. Use a color‑contrast analyzer to evaluate the UI elements (labels, error messages, buttons).  \n2. Increase the browser font size to 200 % and verify that the layout remains usable.\n\n**Expected Outcome**  \nAll text meets the minimum contrast ratio of 4.5:1, and the interface remains functional at larger font sizes.\n\n---\n\n### 16. User Experience – Confirmation & Notification Delivery\n\n**Objective**  \nValidate that confirmation emails and push notifications are sent reliably.\n\n**Steps**  \n1. Update a limit value.  \n2. Check the user’s registered email inbox for a confirmation message.  \n3. Verify that a push notification appears on the mobile device (if enabled).\n\n**Expected Outcome**  \nBoth the email and push notification are delivered within 2 minutes, contain the correct updated values, and include a link to view the activity history.\n\n---\n\n### 17. Scalability – Queue Depth\n\n**Objective**  \nAssess the system’s ability to queue limit‑change requests when the backend service is temporarily overloaded.\n\n**Steps**  \n1. Simulate a backend service slowdown (e.g., by adding artificial latency).  \n2. Submit multiple limit‑change requests in rapid succession.  \n3. Observe queue depth and processing time.\n\n**Expected Outcome**  \nRequests are queued without loss, queue depth does not exceed the configured maximum, and each request is processed within an acceptable SLA.\n\n---\n\n### 18. Reliability – Backup & Restore of User Settings\n\n**Objective**  \nConfirm that a user’s limit settings can be restored from a backup after a data loss event.\n\n**Steps**  \n1. Perform a limit update.  \n2. Take a database backup.  \n3. Delete the user’s limit record from the database.  \n4. Restore from the backup.  \n5. Verify that the user’s limits are restored to the last saved values.\n\n**Expected Outcome**  \nThe backup contains the correct limit values, and restoration restores the user’s settings accurately.\n\n---\n\n### 19. Maintainability – API Rate Limiting\n\n**Objective**  \nEnsure that the limit‑update API enforces rate limiting to prevent abuse.\n\n**Steps**  \n1. Send **50** rapid successive API requests to update limits from the same IP address.  \n2. Monitor the HTTP status codes returned.\n\n**Expected Outcome**  \nAfter a predefined threshold (e.g., 30 requests per minute), the API returns a **429 Too Many Requests** status and a clear error message.\n\n---\n\n### 20. Usability – Error Message Clarity\n\n**Objective**  \nValidate that error messages are user‑friendly and actionable.\n\n**Steps**  \n1. Enter an out‑of‑range limit value (e.g., 0 or a value exceeding the bank’s maximum).  \n2. Submit the change.  \n3. Read the error message displayed.\n\n**Expected Outcome**  \nThe message clearly states the reason (e.g., “Daily purchase limit must be between $10 and $5,000”) and provides guidance on acceptable values.\n\n---\n\n**End of Non‑Functional Test Cases**  \n\nThese scenarios collectively cover performance, security, usability, reliability, compatibility, and regulatory aspects of the “Update Debit Card Limits” feature.  Each can be expanded into automated or manual tests as required by the organization’s testing framework.",
                "reasoning": "We need to generate non-functional test cases for the use case \"Update Debit Card Limits\". Non-functional test cases cover performance, security, usability, reliability, compatibility, etc. We need to present them in non-tabular format, meaning narrative or bullet list but not a table. Provide test scenarios covering non-functional aspects: performance, load, scalability, security, usability, reliability, availability, maintainability, etc. Each test case should have description, steps, expected outcome. Should be in non-tabular format, maybe numbered list with sections. Provide thorough coverage. Let's produce."
            },
            "logprobs": null,
            "finish_reason": "stop"
        }
    ],
    "usage": {
        "queue_time": 0.045956131,
        "prompt_tokens": 286,
        "prompt_time": 0.0161449,
        "completion_tokens": 2558,
        "completion_time": 2.685566022,
        "total_tokens": 2844,
        "total_time": 2.701710922
    },
    "usage_breakdown": null,
    "system_fingerprint": "fp_77f8660d1d",
    "x_groq": {
        "id": "req_01k7pnkzbvfbdt43za8z70388n"
    },
    "service_tier": "on_demand"
}

=============== Formatted output from response using chatgpt=================
1. Performance – Response Time

Objective:
Verify that the limit‑update operation completes within the target response time under normal load.

Steps:

Log in to the banking application using a valid user account.

Navigate to the “Debit Card Limits” screen.

Change the daily purchase limit to a value within the allowed range.

Submit the change.

Record the time from the click of the “Submit” button to the appearance of the confirmation message.

Expected Outcome:
The total response time should be less than 2 seconds for a single transaction on a standard network connection.

2. Performance – Load & Concurrency

Objective:
Ensure that the system can handle multiple simultaneous limit‑update requests without degradation.

Steps:

Simulate 200 concurrent users (e.g., via a load‑testing tool).

Each simulated user logs in, navigates to the limits screen, and submits a valid limit change.

Monitor the average response time and error rate.

Expected Outcome:
Average response time remains below 3 seconds and error rate stays under 1%.

3. Security – Authentication & Session Management

Objective:
Confirm that only authenticated sessions can perform limit changes and that session tokens expire correctly.

Steps:

Log in using a valid account and obtain a session token.

In a separate browser tab, delete the session cookie or invalidate the token.

Attempt to submit a limit change.

Observe the system’s response.

Expected Outcome:
The system rejects the request, displays an authentication error, and redirects the user to the login page.

4. Security – Input Validation & Injection Prevention

Objective:
Verify that the system rejects malformed or malicious input and is resistant to injection attacks.

Steps:

On the limits screen, enter a SQL injection string (e.g., 1; DROP TABLE Users;) into the limit field.

Submit the change.

Repeat with a script injection (<script>alert('XSS')</script>).

Expected Outcome:
The system treats the input as invalid, returns a generic “Invalid value” error, and does not execute any unintended commands or scripts.

5. Security – Data Encryption in Transit & At Rest

Objective:
Confirm that all data exchanged during the limit‑update process is encrypted.

Steps:

Capture network traffic using a packet sniffer while performing a limit change.

Inspect the payload to ensure it is not plain text.

Verify that the database stores limit values in an encrypted field (via a database audit tool).

Expected Outcome:
All transmitted data is protected by TLS 1.2+ and stored values are encrypted with a secure key‑management system.

6. Usability – Accessibility

Objective:
Ensure that the limits screen is accessible to users with disabilities.

Steps:

Load the limits page in a screen‑reader environment (e.g., NVDA or VoiceOver).

Navigate the form using only keyboard shortcuts.

Verify that all form controls have descriptive labels and that error messages are announced.

Expected Outcome:
The screen is fully navigable via keyboard, labels are correctly read by the screen‑reader, and error messages are conveyed audibly.

7. Reliability – Error Handling & Recovery

Objective:
Validate that the system gracefully handles transient failures during a limit update.

Steps:

Simulate a database connection drop just before submitting the change.

Attempt to submit the new limits.

Observe the system’s response and retry logic.

Expected Outcome:
The system displays a user‑friendly error message (“Unable to process request. Please try again.”), logs the failure, and allows the user to retry without losing entered data.

8. Availability – Redundancy & Failover

Objective:
Confirm that the limit‑update feature remains available during a server failover.

Steps:

Trigger a planned failover of the application server (e.g., by stopping the primary instance).

While the failover is in progress, attempt to update limits from a client device.

Monitor whether the request is routed to the standby instance and processed.

Expected Outcome:
The request is handled by the standby server, the user receives the confirmation message, and no downtime is experienced.

9. Scalability – Data Volume

Objective:
Ensure that the audit trail can grow without impacting performance.

Steps:

Perform limit updates repeatedly (e.g., 10,000 times) for a single user.

Measure the time to retrieve the user’s activity history after each batch of updates.

Expected Outcome:
Retrieval time increases linearly but remains within acceptable limits (< 5 seconds for 10,000 records).

10. Maintainability – Logging & Monitoring

Objective:
Verify that all limit changes are properly logged and can be monitored.

Steps:

Update a limit value.

Inspect the application logs to confirm that an entry is created with user ID, timestamp, old value, new value, and transaction ID.

Check that monitoring dashboards (e.g., Splunk, ELK) display the event in real time.

Expected Outcome:
Logs are complete, structured, and searchable; monitoring alerts fire if the rate of limit changes exceeds a predefined threshold.

11. Compatibility – Browser & Device

Objective:
Confirm that the limits screen functions correctly across supported browsers and devices.

Steps:

Open the banking application on Chrome, Firefox, Safari, Edge, and Internet Explorer 11.

Repeat the limit‑update flow on each browser.

Perform the same flow on mobile browsers (iOS Safari, Android Chrome) and on the native mobile app.

Expected Outcome:
All browsers and devices display the form correctly, accept input, and show the confirmation message without layout issues.

12. Internationalization & Localization

Objective:
Ensure that the limits screen displays correctly in supported languages.

Steps:

Switch the application language to Spanish, French, and Arabic.

Navigate to the limits screen and perform a limit update.

Verify that all text, error messages, and numbers are correctly translated and formatted (e.g., currency symbols, decimal separators).

Expected Outcome:
The UI reflects the selected language accurately, and number formatting follows locale conventions.

13. Disaster Recovery – Data Integrity

Objective:
Validate that limit changes survive a catastrophic failure and can be restored.

Steps:

Back up the database snapshot immediately after a limit update.

Simulate a data loss event (e.g., delete the relevant table).

Restore from the backup.

Verify that the limit values and audit records are intact.

Expected Outcome:
Restored data matches the state before the failure; the user’s updated limits are preserved.

14. Regulatory Compliance – Data Retention

Objective:
Confirm that audit logs are retained for the mandated period (e.g., 7 years) and are protected from tampering.

Steps:

Review the audit log retention policy in the system configuration.

Verify that log entries older than the retention period are archived or deleted automatically.

Attempt to modify an old audit record and confirm that the system blocks the action.

Expected Outcome:
Audit logs comply with regulatory requirements, are immutable, and are purged or archived according to policy.

15. Accessibility – Color Contrast & Font Size

Objective:
Ensure that the limits screen meets WCAG 2.1 AA guidelines for color contrast and font scaling.

Steps:

Use a color‑contrast analyzer to evaluate the UI elements (labels, error messages, buttons).

Increase the browser font size to 200% and verify that the layout remains usable.

Expected Outcome:
All text meets the minimum contrast ratio of 4.5:1, and the interface remains functional at larger font sizes.

16. User Experience – Confirmation & Notification Delivery

Objective:
Validate that confirmation emails and push notifications are sent reliably.

Steps:

Update a limit value.

Check the user’s registered email inbox for a confirmation message.

Verify that a push notification appears on the mobile device (if enabled).

Expected Outcome:
Both the email and push notification are delivered within 2 minutes, contain the correct updated values, and include a link to view the activity history.

17. Scalability – Queue Depth

Objective:
Assess the system’s ability to queue limit‑change requests when the backend service is temporarily overloaded.

Steps:

Simulate a backend service slowdown (e.g., by adding artificial latency).

Submit multiple limit‑change requests in rapid succession.

Observe queue depth and processing time.

Expected Outcome:
Requests are queued without loss, queue depth does